{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Development Pipelines with DVC\n",
    "\n",
    "In this notebook we will highlight important elements of DVC. You can find extensive information for dvc on their [website](https://dvc.org).\n",
    "\n",
    "As a showcase we will implement a simple classification pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[39m\u001b[31m|\u001b[39m                                                                     \u001b[31m|\u001b[39m\n",
      "\u001b[31m|\u001b[39m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[39m\n",
      "\u001b[31m|\u001b[39m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[39m\n",
      "\u001b[31m|\u001b[39m              \u001b[34mhttps://dvc.org/doc/user-guide/analytics\u001b[39m               \u001b[31m|\u001b[39m\n",
      "\u001b[31m|\u001b[39m                                                                     \u001b[31m|\u001b[39m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[39m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: \u001b[34mhttps://dvc.org/doc\u001b[39m\n",
      "- Get help and share ideas: \u001b[34mhttps://dvc.org/chat\u001b[39m\n",
      "- Star us on GitHub: \u001b[34mhttps://github.com/iterative/dvc\u001b[39m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# --no-scm because we don't want to interfere with the workshops' git\n",
    "!dvc init -f --no-scm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: We add a new remote storage (could be S3, GCS, SSH, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'local_storage' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d -f local_storage /tmp/dvc_introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our current status. Attention: DVC does not have a sophisticated git-like `stage area`, but a cache-directory, that is being synced with the remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and pipelines are up to date.                                              \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc status -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't too surprising..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either add files to our DVC versioning by manually adding them or implicitly in a pipeline."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!dvc add mybigfile.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\n",
      "\tpython dvc_introduction.py configure output-introduction/config.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 11:28:36.093266: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:36.093592: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:36.093648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "dvc run -f configure.dvc \\\n",
    "        -d dvc_introduction.py \\\n",
    "        -o output-introduction/config.pickle \\\n",
    "        python dvc_introduction.py configure output-introduction/config.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\n",
      "\tpython dvc_introduction.py train_model ../00-datasets/iris.data.csv output-introduction/config.pickle output-introduction/model\n",
      "Train for 15 steps\n",
      "Epoch 1/2\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.9422 - accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 11:28:42.152258: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:42.152628: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:42.152683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-02-19 11:28:43.952509: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:43.952577: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-02-19 11:28:43.952612: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (70e28a9b7a86): /proc/driver/nvidia/version does not exist\n",
      "2020-02-19 11:28:43.953180: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-02-19 11:28:43.963143: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz\n",
      "2020-02-19 11:28:43.963657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564a445513f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-02-19 11:28:43.963714: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-02-19 11:28:44.709177: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "dvc run -f train.dvc \\\n",
    "        -d dvc_introduction.py \\\n",
    "        -d output-introduction/config.pickle \\\n",
    "        -d ../00-datasets/iris.data.csv \\\n",
    "        -o output-introduction/model \\\n",
    "        python dvc_introduction.py train_model ../00-datasets/iris.data.csv \\\n",
    "                                               output-introduction/config.pickle \\\n",
    "                                               output-introduction/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\n",
      "\tpython dvc_introduction.py export output-introduction/model ../04-models/iris/2\n",
      "Output '../04-models/iris/2' doesn't use cache. Skipping saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 11:28:49.098102: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:49.098264: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:49.098282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-02-19 11:28:50.883051: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-02-19 11:28:50.883111: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-02-19 11:28:50.883139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (70e28a9b7a86): /proc/driver/nvidia/version does not exist\n",
      "2020-02-19 11:28:50.883311: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-02-19 11:28:50.889856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2712000000 Hz\n",
      "2020-02-19 11:28:50.890229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5636e231aca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-02-19 11:28:50.890275: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-02-19 11:28:51.529297: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "dvc run -f Dvcfile \\\n",
    "        -d dvc_introduction.py \\\n",
    "        -d output-introduction/model \\\n",
    "        -O ../04-models/iris/2 \\\n",
    "        python dvc_introduction.py export output-introduction/model ../04-models/iris/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting and Modifying a Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+  \n",
      "| configure.dvc |  \n",
      "+---------------+  \n",
      "        *          \n",
      "        *          \n",
      "        *          \n",
      "  +-----------+    \n",
      "  | train.dvc |    \n",
      "  +-----------+    \n",
      "        *          \n",
      "        *          \n",
      "        *          \n",
      "   +---------+     \n",
      "   | Dvcfile |     \n",
      "   +---------+     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: assuming default target 'Dvcfile'.\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "dvc pipeline show --ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnew:                output-introduction/model                                  \n",
      "\tnew:                output-introduction/model/saved_model.pb\n",
      "\tnew:                output-introduction/model/variables/variables.data-00000-of-00001\n",
      "\tnew:                output-introduction/model/variables/variables.index\n",
      "\tnew:                output-introduction/config.pickle\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc status -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0% output-introduction/model|                 |0.00/258 [00:00<?,        ?B/s]\n",
      "!\u001b[A\n",
      "  0%|          |output-introduction/model/variab0.00/210k [00:00<?,        ?B/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |output-introduction/model/saved0.00/86.4k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "!\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          |output-introduction/model/varia0.00/1.68k [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A                                                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                                                       \n",
      "\n",
      "                                                                                \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |output-introduction/config.pickle0.00/139 [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                                                          \n",
      "\u001b[A\n",
      "\u001b[A\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[39m: assuming default target 'Dvcfile'.\n",
      "Data and pipelines are up to date.                                              \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify a file and reproduce our pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a file from another (external) git+DVC repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 'model.pkl (https://github.com/iterative/example-get-started)' -> 'model.pkl'\n",
      "\u001b[0m                                                                            "
     ]
    }
   ],
   "source": [
    "!dvc import https://github.com/iterative/example-get-started model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m                                                                            "
     ]
    }
   ],
   "source": [
    "!dvc get https://github.com/iterative/example-get-started model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a file *including* its .dvc file from another (external) git+DVC repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features in real life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics and evaluation\n",
    "Metrics can be used to track scores and evaluations over all branches\n",
    "\n",
    "```bash\n",
    "$ dvc metrics show --all-branches\n",
    "experiment1:\n",
    "    metrics.json: {\"loss\": 0.0012, \"accuracy\": 0.9765}\n",
    "experiment2:\n",
    "    metrics.json: {\"loss\": 0.0010, \"accuracy\": 0.9865}\n",
    "working tree:\n",
    "    metrics.json: {\"loss\": 0.0010, \"accuracy\": 0.9865}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Releasing and Deployment with git tags\n",
    "Git tags can be used to keep track over releases:\n",
    "\n",
    "```bash\n",
    "$ git checkout master\n",
    "$ git merge experiment2\n",
    "$ git tag -a release/0.1 -m \"0.1 release\"\n",
    "```\n",
    "\n",
    "And use DVC get to download the release (e.g. using a deploy job)\n",
    "```bash\n",
    "$ GIT_REPO=...\n",
    "$ dvc get --rev release/0.1 $GIT_REPO model.h5\n",
    "```\n",
    "\n",
    "Even metrics can be used to get an overview over the releases and their performance:\n",
    "\n",
    "```bash\n",
    "$ dvc metrics show -T\n",
    "release/0.1:\n",
    "    metrics.json: {\"loss\": 0.0112, \"accuracy\": 0.9865}\n",
    "working tree:\n",
    "    metrics.json: {\"loss\": 0.0112, \"accuracy\": 0.9865}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug only - pls ignore :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "rm -rf .dvc\n",
    "rm -rf *.dvc\n",
    "rm Dvcfile\n",
    "rm -rf /tmp/dvc_introduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
